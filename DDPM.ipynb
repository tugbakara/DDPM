{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19299,"status":"ok","timestamp":1744704108642,"user":{"displayName":"Tuğba Kara","userId":"01463010389261867736"},"user_tz":-180},"id":"I2nsdfkf49In","outputId":"42350bf2-dc56-41fd-bad5-a72adbf90e34"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":9532,"status":"ok","timestamp":1744704118175,"user":{"displayName":"Tuğba Kara","userId":"01463010389261867736"},"user_tz":-180},"id":"ONJCs2EDknm7"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","from torchvision import transforms\n","from torch.utils.data.dataloader import DataLoader\n","from torch.utils.data.dataset import Dataset\n","from torchvision.utils import make_grid\n","import glob\n","import os\n","import random\n","import shutil\n","from PIL import Image\n","import zipfile\n","from tqdm import tqdm\n","import numpy as np\n","import multiprocessing\n","from concurrent.futures import ThreadPoolExecutor"]},{"cell_type":"markdown","metadata":{"id":"xh3TcJgZGKme"},"source":["## **Configuration Params**"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1744704118183,"user":{"displayName":"Tuğba Kara","userId":"01463010389261867736"},"user_tz":-180},"id":"FtsXDf-vPb5U"},"outputs":[],"source":["config = {\n","    'dataset_params': {\n","        'im_path': '/content/drive/MyDrive/DDPM/afhq'\n","    },\n","    'diffusion_params': {\n","        'num_timesteps': 800,\n","        'beta_start': 0.0001,\n","        'beta_end': 0.02\n","    },\n","    'model_params': {\n","        'im_channels': 3,\n","        'im_size': 64,\n","        'encode_channels': [32, 64, 128, 256],\n","        'mid_channels': [256, 256, 128],\n","        'down_sample': [True, True, True, False],\n","        'time_emb_dim': 128,\n","        'num_encode_layers': 2,\n","        'num_mid_layers': 2,\n","        'num_decode_layers': 2,\n","        'num_heads': 4\n","    },\n","    'train_params': {\n","        'task_name': '/content/drive/MyDrive/DDPM/first_ddpm_training',\n","        'batch_size': 8,\n","        'num_epochs': 64,\n","        'num_samples': 20,\n","        'num_grid_rows': 5,\n","        'lr': 0.0001,\n","        'ckpt_name': '/content/drive/MyDrive/DDPM/ddpm_ckpt.pth'\n","    }\n","}"]},{"cell_type":"markdown","metadata":{"id":"oY9S3gnl5oHd"},"source":["## **Noise Scheduler**"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1744704118191,"user":{"displayName":"Tuğba Kara","userId":"01463010389261867736"},"user_tz":-180},"id":"nXGJHqde5kyl"},"outputs":[],"source":["class NoiseScheduler:\n","  def __init__(self, timesteps, beta_start, beta_end):\n","    self.num_timestemps = timesteps\n","    self.beta_start = beta_start\n","    self.beta_end = beta_end\n","\n","    self.betas = torch.linspace(self.beta_start, self.beta_end, self.num_timestemps)\n","    self.alphas = 1. - self.betas\n","    self.alpha_cumulative_product = torch.cumprod(self.alphas, dim=0)\n","    self.sqrt_alpha_cumulative_product = torch.sqrt(self.alpha_cumulative_product)\n","    self.sqrt_one_min_alpha_cumulative_product = torch.sqrt(1-self.alpha_cumulative_product)\n","\n","  def add_noise(self, img, noise, t):\n","    img_shape = img.shape\n","    batch_size = img_shape[0]\n","\n","    sqrt_alpha_cumulative_product = self.sqrt_alpha_cumulative_product.to(img.device)[t].reshape(batch_size)\n","    sqrt_one_min_alpha_cumulative_product= self.sqrt_one_min_alpha_cumulative_product.to(img.device)[t].reshape(batch_size)\n","    for _ in range(len(img_shape) - 1):\n","      sqrt_alpha_cumulative_product = sqrt_alpha_cumulative_product.unsqueeze(-1)\n","    for _ in range(len(img_shape) - 1):\n","      sqrt_one_min_alpha_cumulative_product = sqrt_one_min_alpha_cumulative_product.unsqueeze(-1)\n","    return (sqrt_alpha_cumulative_product * img) + sqrt_one_min_alpha_cumulative_product * noise\n","\n","  def remove_noise(self, xt, noise_pred, t):\n","    x0 = (xt - (self.sqrt_one_min_alpha_cumulative_product.to(xt.device)[t] * noise_pred))/(self.sqrt_alpha_cumulative_product.to(xt.device)[t])\n","    x0 = torch.clamp(x0, -1., 1.)\n","    mean = (xt - (self.betas.to(xt.device)[t] * noise_pred) / (self.sqrt_one_min_alpha_cumulative_product.to(xt.device)[t]))\n","    mean = mean / torch.sqrt(self.alphas.to(xt.device)[t])\n","    if t == 0:\n","      return mean, x0\n","    else:\n","      variance = (1 - self.alpha_cumulative_product.to(xt.device)[t -1 ]) / (1 - self.alpha_cumulative_product.to(xt.device)[t])\n","      variance = variance * self.betas.to(xt.device)[t]\n","      sigma = variance ** 0.5\n","      z = torch.randn(xt.shape).to(xt.device)\n","      return mean + sigma * z, x0"]},{"cell_type":"markdown","metadata":{"id":"BVsxE1_N0RhG"},"source":["## **UNET + Time Embedding**"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1744704118194,"user":{"displayName":"Tuğba Kara","userId":"01463010389261867736"},"user_tz":-180},"id":"gdmHQjcD0eVg"},"outputs":[],"source":["def time_embedding(time_steps, time_embedding_dim):\n","  assert time_embedding_dim % 2 == 0, \"time embedding dimension must be divisible by 2\"\n","  factor =  10000 ** ((torch.arange(start=0, end= time_embedding_dim//2, dtype= torch.float32, device=time_steps.device)))\n","  time_embedding = time_steps[:, None].repeat(1, time_embedding_dim//2) / factor\n","  time_embedding = torch.cat([torch.sin(time_embedding), torch.cos(time_embedding)], dim=-1)\n","  return time_embedding"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1744704118214,"user":{"displayName":"Tuğba Kara","userId":"01463010389261867736"},"user_tz":-180},"id":"IPYk_Cc4aEM2"},"outputs":[],"source":["class encoder(nn.Module):\n","  def __init__(self, ip_ch, op_ch, time_embedding_dim, down_sample=True, num_heads=4, num_layers=1):\n","    super().__init__()\n","    self.number_layers = num_layers\n","    self.down_sample = down_sample\n","\n","    self.resnet_first = nn.ModuleList(\n","        [\n","        nn.Sequential(\n","            nn.GroupNorm(8, ip_ch if i == 0 else op_ch),\n","            nn.SiLU(),\n","            nn.Conv2d(ip_ch if i == 0 else op_ch, op_ch, kernel_size=3, stride=1, padding=1)\n","          )\n","          for i in range(self.number_layers)\n","        ]\n","    )\n","\n","    self.time_embedding_layer = nn.ModuleList([\n","        nn.Sequential(\n","            nn.SiLU(),\n","            nn.Linear(time_embedding_dim, op_ch)\n","            )\n","            for _ in range(self.number_layers)\n","        ]\n","    )\n","\n","    self.resnet_second = nn.ModuleList(\n","        [\n","            nn.Sequential(\n","                nn.GroupNorm(8, op_ch),\n","                nn.SiLU(),\n","                nn.Conv2d(op_ch, op_ch, kernel_size=3, stride=1, padding=1),\n","            )\n","            for _ in range(self.number_layers)\n","        ]\n","    )\n","    self.attention_normalization = nn.ModuleList(\n","        [\n","            nn.GroupNorm(8,op_ch) for _ in range(self.number_layers)\n","        ]\n","    )\n","\n","    self.attention = nn.ModuleList([\n","        nn.MultiheadAttention(op_ch, num_heads, batch_first=True)\n","        for _ in range(self.number_layers)]\n","    )\n","\n","    self.residual_ip = nn.ModuleList(\n","        [\n","            nn.Conv2d(ip_ch if i == 0 else op_ch, op_ch, kernel_size=1)\n","            for i in range(self.number_layers)\n","        ]\n","    )\n","\n","    self.down_sample = nn.Conv2d(op_ch,op_ch,4,2,1) if self.down_sample else nn.Identity()\n","\n","  def forward(self, x, time_embedding):\n","    op = x\n","    for i in range(self.number_layers):\n","      resnet_ip = op\n","      op = self.resnet_first[i](op)\n","      op = op + self.time_embedding_layer[i](time_embedding)[:, :, None, None]\n","      op = self.resnet_second[i](op)\n","      op = op + self.residual_ip[i](resnet_ip)\n","      batch_size, channels, h, w = op.shape\n","      ip_att = op.reshape(batch_size, channels, h*w)\n","      ip_att = self.attention_normalization[i](ip_att)\n","      ip_att = ip_att.transpose(1,2)\n","      op_att, _ = self.attention[i](ip_att, ip_att, ip_att)\n","      op_att = op_att.transpose(1,2).reshape(batch_size, channels, h, w)\n","      op = op + op_att\n","    op = self.down_sample(op)\n","    return op\n"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1744704118225,"user":{"displayName":"Tuğba Kara","userId":"01463010389261867736"},"user_tz":-180},"id":"hNzSx-zNr-Fa"},"outputs":[],"source":["class UNetMid(nn.Module):\n","  def __init__(self,ip_ch,op_ch,time_embedding_dim,num_heads=4,num_layers=1):\n","    super().__init__()\n","    self.number_layers = num_layers\n","\n","    self.resnet_first = nn.ModuleList(\n","        [\n","            nn.Sequential(\n","                nn.GroupNorm(8, ip_ch if i == 0 else op_ch),\n","                nn.SiLU(),\n","                nn.Conv2d(ip_ch if i==0 else op_ch, op_ch, kernel_size=3, stride=1, padding=1),\n","            )\n","            for i in range(self.number_layers + 1)\n","        ]\n","    )\n","\n","    self.time_embedding_layer = nn.ModuleList(\n","        [\n","            nn.Sequential(\n","                nn.SiLU(),\n","                nn.Linear(time_embedding_dim, op_ch)\n","            )\n","            for _ in range(self.number_layers + 1)\n","        ]\n","    )\n","\n","    self.resnet_second = nn.ModuleList(\n","        [\n","            nn.Sequential(\n","                nn.GroupNorm(8,op_ch),\n","                nn.SiLU(),\n","                nn.Conv2d(op_ch, op_ch, kernel_size=3, stride=1, padding=1),\n","            )\n","            for _ in range(self.number_layers + 1)\n","        ]\n","    )\n","\n","    self.attention_normalization = nn.ModuleList(\n","        [\n","            nn.GroupNorm(8, op_ch) for _ in range(self.number_layers)\n","        ]\n","    )\n","\n","    self.attention = nn.ModuleList(\n","        [\n","            nn.MultiheadAttention(op_ch,num_heads, batch_first=True) for _ in range(self.number_layers)\n","        ]\n","    )\n","\n","    self.residual_ip = nn.ModuleList(\n","        [\n","            nn.Conv2d(ip_ch if i == 0 else op_ch, op_ch, kernel_size=1) for i in range(self.number_layers + 1)\n","        ]\n","    )\n","\n","\n","  def forward(self,x,time_embedding):\n","    op = x\n","    resnet_ip = op\n","    op = self.resnet_first[0](op)\n","    op = op + self.time_embedding_layer[0](time_embedding)[:, :, None, None]\n","    op = self.resnet_second[0](op)\n","    op = op +  self.residual_ip[0](resnet_ip)\n","    for i in range(self.number_layers):\n","      batch_size, channels, h, w = op.shape\n","      ip_att = op.reshape(batch_size, channels, h*w)\n","      ip_att = self.attention_normalization[i](ip_att)\n","      ip_att = ip_att.transpose(1,2)\n","      op_att, _ = self.attention[i](ip_att, ip_att, ip_att)\n","      op_att = op_att.transpose(1,2).reshape(batch_size, channels, h, w)\n","      op = op + op_att\n","      resnet_ip = op\n","      op = self.resnet_first[i+1](op)\n","      op = op + self.time_embedding_layer[i+1](time_embedding)[:, :, None, None]\n","      op = self.resnet_second[i+1](op)\n","      op = op + self.residual_ip[i+1](resnet_ip)\n","    return op"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":97,"status":"ok","timestamp":1744704118324,"user":{"displayName":"Tuğba Kara","userId":"01463010389261867736"},"user_tz":-180},"id":"EwnmrVyv0neS"},"outputs":[],"source":["class decoder(nn.Module):\n","  def __init__(self, ip_ch, op_ch, time_embedding_dim, up_sample=True, num_heads=4, num_layers=1):\n","    super().__init__()\n","    self.number_layers = num_layers\n","    self.up_sample = up_sample\n","\n","    self.resnet_first = nn.ModuleList(\n","        [\n","            nn.Sequential(\n","                nn.GroupNorm(8, ip_ch if i ==0 else op_ch),\n","                nn.SiLU(),\n","                nn.Conv2d(ip_ch if i == 0 else op_ch, op_ch, kernel_size=3, stride=1, padding=1)\n","            )\n","            for i in range(self.number_layers)\n","        ]\n","    )\n","\n","    self.time_embedding_layer = nn.ModuleList(\n","        [\n","            nn.Sequential(\n","                nn.SiLU(),\n","                nn.Linear(time_embedding_dim, op_ch)\n","            )\n","            for _ in range(self.number_layers)\n","        ]\n","\n","    )\n","\n","    self.resnet_second = nn.ModuleList(\n","        [\n","            nn.Sequential(\n","                nn.GroupNorm(8, op_ch),\n","                nn.SiLU(),\n","                nn.Conv2d(op_ch, op_ch, kernel_size=3, stride=1, padding=1)\n","            )\n","            for _ in range(self.number_layers)\n","        ]\n","    )\n","\n","    self.attention_normalization = nn.ModuleList(\n","        [\n","            nn.GroupNorm(8, op_ch) for _ in range(self.number_layers)\n","        ]\n","    )\n","\n","    self.attention = nn.ModuleList(\n","        [\n","            nn.MultiheadAttention(op_ch, num_heads, batch_first=True) for _ in range(self.number_layers)\n","        ]\n","    )\n","\n","    self.residual_ip = nn.ModuleList(\n","        [\n","            nn.Conv2d(ip_ch if i == 0 else op_ch, op_ch, kernel_size=1) for i in range(self.number_layers)\n","        ]\n","    )\n","\n","    self.up_sample = nn.ConvTranspose2d(ip_ch //2, ip_ch // 2, 4, 2, 1) if self.up_sample else nn.Identity()\n","\n","  def forward(self, x, op_down, time_embedding):\n","    x = self.up_sample(x)\n","    x = torch.cat([x, op_down], dim=1)\n","    op = x\n","    for i in range(self.number_layers):\n","      resnet_ip = op\n","      op = self.resnet_first[i](op)\n","      op = op + self.time_embedding_layer[i](time_embedding)[:, :, None, None]\n","      op = self.resnet_second[i](op)\n","      op = op + self.residual_ip[i](resnet_ip)\n","      batch_size, channels, h, w = op.shape\n","      ip_att = op.reshape(batch_size, channels, h*w)\n","      ip_att = self.attention_normalization[i](ip_att)\n","      ip_att = ip_att.transpose(1,2)\n","      op_att, _ = self.attention[i](ip_att, ip_att, ip_att)\n","      op_att = op_att.transpose(1,2).reshape(batch_size, channels, h, w)\n","      op = op + op_att\n","    return op\n"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1744704118330,"user":{"displayName":"Tuğba Kara","userId":"01463010389261867736"},"user_tz":-180},"id":"wHSaijjpeQTI"},"outputs":[],"source":["class UNet(nn.Module):\n","  def __init__(self,model_config):\n","    super().__init__()\n","    model_params = config['model_params']\n","    img_ch = model_params['im_channels']\n","    self.encode_ch = model_params['encode_channels']\n","    self.mid_ch = model_params['mid_channels']\n","    self.time_embedding_dim = model_params['time_emb_dim']\n","    self.down_sample = model_params['down_sample']\n","    self.num_encode_layers = model_params['num_encode_layers']\n","    self.num_mid_layers = model_params['num_mid_layers']\n","    self.num_decode_layers = model_params['num_decode_layers']\n","\n","    assert self.mid_ch[0] == self.encode_ch[-1]\n","    assert self.mid_ch[-1] == self.encode_ch[-2]\n","    assert len(self.down_sample) == len(self.encode_ch)\n","\n","    self.time_projection = nn.Sequential(\n","        nn.Linear(self.time_embedding_dim, self.time_embedding_dim),\n","        nn.SiLU(),\n","        nn.Linear(self.time_embedding_dim, self.time_embedding_dim)\n","    )\n","\n","    self.decode_sample = list(reversed(self.down_sample))\n","    self.encode_ip = nn.Conv2d(img_ch, self.encode_ch[0], kernel_size=3, padding=(1,1))\n","\n","    self.encode = nn.ModuleList([])\n","    for i in range(len(self.encode_ch) - 1):\n","      self.encode.append(encoder(self.encode_ch[i], self.encode_ch[i+1], self.time_embedding_dim, down_sample=self.down_sample[i], num_layers=self.num_encode_layers))\n","\n","    self.mid = nn.ModuleList([])\n","    for i in range(len(self.mid_ch) - 1):\n","      self.mid.append(UNetMid(self.mid_ch[i], self.mid_ch[i+1], self.time_embedding_dim, num_layers=self.num_mid_layers))\n","\n","    self.decode = nn.ModuleList([])\n","    for i in reversed(range(len(self.encode_ch) - 1)):\n","      self.decode.append(decoder(self.encode_ch[i] * 2, self.encode_ch[i-1] if i!= 0 else 16, self.time_embedding_dim, up_sample=self.down_sample[i], num_layers=self.num_decode_layers))\n","\n","    self.norm_op = nn.GroupNorm(8,16)\n","    self.decode_op = nn.Conv2d(16, img_ch, kernel_size=3, padding=1)\n","\n","  def forward(self,x,t):\n","    op = self.encode_ip(x)\n","    time_embeddings = time_embedding(torch.as_tensor(t).long(), self.time_embedding_dim)\n","    time_embeddings = self.time_projection(time_embeddings)\n","    encode_op = []\n","\n","    for idx, encodes in enumerate(self.encode):\n","      encode_op.append(op)\n","      op = encodes(op, time_embeddings)\n","\n","    for mids in self.mid:\n","      op = mids(op, time_embeddings)\n","\n","    for decodes in self.decode:\n","      op = decodes(op, encode_op.pop(), time_embeddings)\n","\n","    op = self.norm_op(op)\n","    op = nn.SiLU()(op)\n","    op = self.decode_op(op)\n","    return op\n"]},{"cell_type":"markdown","metadata":{"id":"s8F2-IJmvh0H"},"source":["##**Dataset Load**"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1744704118337,"user":{"displayName":"Tuğba Kara","userId":"01463010389261867736"},"user_tz":-180},"id":"wwUHTGKb0MYG"},"outputs":[],"source":["# kaggle_json_path = '/content/drive/MyDrive/DDPM/kaggle.json'\n","# if os.path.exists(kaggle_json_path):\n","#     !mkdir -p ~/.kaggle\n","#     !cp '{kaggle_json_path}' ~/.kaggle/\n","#     !chmod 600 ~/.kaggle/kaggle.json\n","#     print(\"Kaggle API başarıyla ayarlandı!\")\n","# else:\n","#     print(f\"HATA: {kaggle_json_path} dosyası bulunamadı!\")\n","#     print(\"Lütfen kaggle.json dosyasını belirtilen yola yüklediğinizden emin olun.\")"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1744704118344,"user":{"displayName":"Tuğba Kara","userId":"01463010389261867736"},"user_tz":-180},"id":"HPJ6gcgD4evJ"},"outputs":[],"source":["# !kaggle datasets download -d dimensi0n/afhq-512\n","\n","# !mv afhq-512.zip '/content/drive/MyDrive/DDPM/afhq'"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1744704118348,"user":{"displayName":"Tuğba Kara","userId":"01463010389261867736"},"user_tz":-180},"id":"4K7Og6Vw6KYN"},"outputs":[],"source":["# zip_path = '/content/drive/MyDrive/DDPM/afhq/afhq-512.zip'\n","# extract_path = '/content/drive/MyDrive/DDPM/afhq'\n","\n","# with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","#     zip_ref.extractall(extract_path)\n","\n","# print(\"Veri seti başarıyla çıkarıldı!\")"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1744704118363,"user":{"displayName":"Tuğba Kara","userId":"01463010389261867736"},"user_tz":-180},"id":"EU2leVIu47oe"},"outputs":[],"source":["# def resize_image(file_path, output_path, target_size=(64, 64)):\n","#     \"\"\"Resize a single image and save it to the output path.\"\"\"\n","#     try:\n","#         with Image.open(file_path) as img:\n","#             img = img.convert('RGB')\n","#             img_resized = img.resize(target_size, Image.LANCZOS)\n","#             img_resized.save(output_path, quality=95)\n","#             return True\n","#     except Exception as e:\n","#         print(f\"Error processing {file_path}: {e}\")\n","#         return False\n","\n","# def resize_images_in_directory(source_dir, target_size=(64, 64)):\n","#     \"\"\"Resize all images in source directory and its subdirectories.\"\"\"\n","#     subdirs = [d for d in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, d))]\n","\n","#     image_files = []\n","#     for subdir in subdirs:\n","#         subdir_path = os.path.join(source_dir, subdir)\n","\n","#         for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:\n","#             pattern = os.path.join(subdir_path, ext)\n","#             image_files.extend(glob.glob(pattern))\n","\n","#     print(f\"Found {len(image_files)} images to resize\")\n","\n","#     num_workers = min(multiprocessing.cpu_count(), 8)\n","#     with ThreadPoolExecutor(max_workers=num_workers) as executor:\n","#         futures = []\n","#         for img_path in image_files:\n","#             relative_path = os.path.relpath(img_path, source_dir)\n","#             output_path = img_path\n","#             futures.append(executor.submit(resize_image, img_path, output_path, target_size))\n","\n","#         success_count = 0\n","#         for future in tqdm(futures, desc=\"Resizing images\"):\n","#             if future.result():\n","#                 success_count += 1\n","\n","#     print(f\"Successfully resized {success_count} out of {len(image_files)} images\")\n","\n","# source_directory = \"/content/drive/MyDrive/DDPM/afhq\"\n","# resize_images_in_directory(source_directory, target_size=(64, 64))"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1744704118370,"user":{"displayName":"Tuğba Kara","userId":"01463010389261867736"},"user_tz":-180},"id":"uPXa7sbf6u5Q"},"outputs":[],"source":["# def reduce_images_in_directory(source_dir):\n","#     subdirs = [d for d in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, d))]\n","\n","#     total_removed = 0\n","\n","#     for subdir in subdirs:\n","#         subdir_path = os.path.join(source_dir, subdir)\n","\n","#         image_files = []\n","#         for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:\n","#             pattern = os.path.join(subdir_path, ext)\n","#             image_files.extend(glob.glob(pattern))\n","\n","#         num_to_keep = len(image_files) // 2\n","\n","#         files_to_remove = random.sample(image_files, len(image_files) - num_to_keep)\n","\n","#         print(f\"Folder {subdir}: Found {len(image_files)} images, keeping {num_to_keep}, removing {len(files_to_remove)}\")\n","\n","#         for file_path in tqdm(files_to_remove, desc=f\"Removing images from {subdir}\"):\n","#             try:\n","#                 os.remove(file_path)\n","#                 total_removed += 1\n","#             except Exception as e:\n","#                 print(f\"Error removing {file_path}: {e}\")\n","\n","#     print(f\"Successfully removed {total_removed} images. Dataset size reduced by approximately 50%.\")\n","\n","# source_directory = \"/content/drive/MyDrive/DDPM/afhq\"\n","# reduce_images_in_directory(source_directory)"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1744704118385,"user":{"displayName":"Tuğba Kara","userId":"01463010389261867736"},"user_tz":-180},"id":"mFyui9eJvqI5"},"outputs":[],"source":["class AFHQDataset(Dataset):\n","    def __init__(self, split, im_path, im_ext='png'):\n","        self.split = split\n","        self.im_ext = im_ext\n","        self.images, self.labels = self.load_images(im_path)\n","\n","        self.transform = transforms.Compose([\n","            transforms.Resize((64, 64)),\n","            transforms.ToTensor(),\n","        ])\n","\n","    def load_images(self, im_path):\n","        assert os.path.exists(im_path), \"images path {} does not exist\".format(im_path)\n","        ims = []\n","        labels = []\n","\n","        class_names = sorted(os.listdir(im_path))  # ['cat', 'dog', 'wild']\n","        class_to_idx = {class_name: idx for idx, class_name in enumerate(class_names)}\n","\n","        for d_name in tqdm(os.listdir(im_path)):\n","            if os.path.isdir(os.path.join(im_path, d_name)):\n","                for fname in glob.glob(os.path.join(im_path, d_name, '*.{}'.format(self.im_ext))):\n","                    ims.append(fname)\n","                    labels.append(class_to_idx[d_name])\n","\n","        print('Found {} images for split {}'.format(len(ims), self.split))\n","        return ims, labels\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        image_path = self.images[idx]\n","        image = Image.open(image_path).convert('RGB')\n","        image = self.transform(image)\n","        label = self.labels[idx]\n","        return image, label"]},{"cell_type":"markdown","metadata":{"id":"DUm7zUGGFJcE"},"source":["## **Trainig**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"collapsed":true,"executionInfo":{"elapsed":51,"status":"error","timestamp":1744701244754,"user":{"displayName":"Tuğba Kara","userId":"01463010389261867736"},"user_tz":-180},"id":"a5UhYmeoFMtW","outputId":"1d87869e-450e-4b69-bff1-9a706be8f18b"},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","def train():\n","  diffusion_config = config['diffusion_params']\n","  dataset_config = config['dataset_params']\n","  model_config = config['model_params']\n","  train_config = config['train_params']\n","\n","  scheduler = NoiseScheduler(timesteps=diffusion_config['num_timesteps'],\n","                             beta_start=diffusion_config['beta_start'],\n","                             beta_end=diffusion_config['beta_end'])\n","  dataset = AFHQDataset('train', dataset_config['im_path'])\n","  dataloader = DataLoader(dataset, batch_size=train_config['batch_size'], shuffle=True, num_workers=8)\n","\n","  model = UNet(model_config).to(device)\n","  model.train()\n","\n","  if not os.path.exists(train_config['task_name']):\n","    os.makedirs(train_config['task_name'])\n","\n","  if os.path.exists(os.path.join(train_config['task_name'], train_config['ckpt_name'])):\n","    print(\"Loding checkpoint...\")\n","    model.load_state_dict(torch.load(os.path.join(train_config['task_name'], train_config['ckpt_name']), map_location=device))\n","\n","  num_epochs = train_config['num_epochs']\n","  optimizer = torch.optim.Adam(model.parameters(), lr=train_config['lr'])\n","  criterion = torch.nn.MSELoss()\n","\n","  for epoch_idx in range(num_epochs):\n","    losses = []\n","    for img, _ in tqdm(dataloader):\n","      optimizer.zero_grad()\n","      img = img.float().to(device)\n","      noise = torch.randn_like(img).to(device)\n","      t = torch.randint(0, diffusion_config['num_timesteps'],(img.shape[0],)).to(device)\n","      noisy_img = scheduler.add_noise(img, noise, t)\n","      noise_pred = model(noisy_img, t)\n","      loss = criterion(noise_pred, noise)\n","      losses.append(loss.item())\n","      loss.backward()\n","      optimizer.step()\n","    print(\"Epoch: {} | Loss: {}\".format(epoch_idx + 1, np.mean(losses)))\n","    torch.save(model.state_dict(), os.path.join(train_config[\"task_name\"], train_config[\"ckpt_name\"]))\n","if __name__ == \"__main__\":\n","  train()"]},{"cell_type":"markdown","metadata":{"id":"xiK319L6FzPU"},"source":["## **Image Generation**"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":182761,"status":"ok","timestamp":1744704301148,"user":{"displayName":"Tuğba Kara","userId":"01463010389261867736"},"user_tz":-180},"id":"Ur6ZM645eTFO","outputId":"d7b8cd9c-24a5-493d-8c0e-322beefa7319"},"outputs":[{"name":"stderr","output_type":"stream","text":["800it [02:46,  4.82it/s]\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","def sample(model, scheduler, train_config, model_config, diffusion_config):\n","  xt = torch.randn((train_config['num_samples'], model_config['im_channels'],model_config['im_size'],model_config['im_size'])).to(device)\n","  for i in tqdm(reversed(range(diffusion_config['num_timesteps']))):\n","    noise_pred = model(xt, torch.as_tensor(i).unsqueeze(0).to(device))\n","    xt, x0_pred = scheduler.remove_noise(xt, noise_pred, torch.as_tensor(i).to(device))\n","    imgs = torch.clamp(xt,-1., 1.).detach().cpu()\n","    imgs = (imgs + 1) / 2\n","    grid = make_grid(imgs, nrow=train_config['num_grid_rows'])\n","    img = torchvision.transforms.ToPILImage()(grid)\n","    if not os.path.exists(os.path.join(train_config['task_name'], 'samples')):\n","      os.makedirs(os.path.join(train_config['task_name'], 'samples'))\n","    img.save(os.path.join(train_config['task_name'], 'samples', 'x0_{}.png'.format(i)))\n","    img.close()\n","\n","def inference():\n","    diffusion_config = config['diffusion_params']\n","    model_config = config['model_params']\n","    train_config = config['train_params']\n","    model = UNet(model_config).to(device)\n","    model.load_state_dict(torch.load(os.path.join(train_config['task_name'],train_config['ckpt_name']),map_location=device))\n","    model.eval()\n","    scheduler = NoiseScheduler(timesteps=diffusion_config['num_timesteps'],\n","                               beta_start=diffusion_config['beta_start'],\n","                               beta_end=diffusion_config['beta_end'])\n","    with torch.no_grad():\n","      sample(model, scheduler, train_config, model_config, diffusion_config)\n","if __name__ == \"__main__\":\n","  inference()"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMpW5+FV5CFcyqfOMOImG61","collapsed_sections":["oY9S3gnl5oHd","BVsxE1_N0RhG","s8F2-IJmvh0H","DUm7zUGGFJcE"],"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
